{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["**Секція 1. Логістична регресія з нуля.**\n","\n","Будемо крок за кроком будувати модель лог регресії з нуля для передбачення, чи буде врожай більше за 80 яблук (задача подібна до лекційної, але на класифікацію).\n","\n","Давайте нагадаємо основні формули для логістичної регресії.\n","\n","### Функція гіпотези - обчислення передбачення у логістичній регресії:\n","\n","$$\n","\\hat{y} = \\sigma(x W^T + b) = \\frac{1}{1 + e^{-(x W^T + b)}}\n","$$\n","\n","Де:\n","- $ \\hat{y} $ — це ймовірність \"позитивного\" класу.\n","- $ x $ — це вектор (або матриця для набору прикладів) вхідних даних.\n","- $ W $ — це вектор (або матриця) вагових коефіцієнтів моделі.\n","- $ b $ — це зміщення (bias).\n","- $ \\sigma(z) $ — це сигмоїдна функція активації.\n","\n","### Як обчислюється сигмоїдна функція:\n","\n","Сигмоїдна функція $ \\sigma(z) $ має вигляд:\n","\n","$$\n","\\sigma(z) = \\frac{1}{1 + e^{-z}}\n","$$\n","\n","Ця функція перетворює будь-яке дійсне значення $ z $ в інтервал від 0 до 1, що дозволяє інтерпретувати вихід як ймовірність для логістичної регресії.\n","\n","### Формула функції втрат для логістичної регресії (бінарна крос-ентропія):\n","\n","Функція втрат крос-ентропії оцінює, наскільки добре модель передбачає класи, порівнюючи передбачені ймовірності $ \\hat{y} $ із справжніми мітками $ y $. Формула наступна:\n","\n","$$\n","L(y, \\hat{y}) = - \\left[ y \\cdot \\log(\\hat{y}) + (1 - y) \\cdot \\log(1 - \\hat{y}) \\right]\n","$$\n","\n","Де:\n","- $ y $ — це справжнє значення (мітка класу, 0 або 1).\n","- $ \\hat{y} $ — це передбачене значення (ймовірність).\n","\n"],"metadata":{"id":"lbLHTNfSclli"}},{"cell_type":"markdown","source":["1.\n","Тут вже наведений код для ініціювання набору даних в форматі numpy. Перетворіть `inputs`, `targets` на `torch` тензори. Виведіть результат на екран."],"metadata":{"id":"GtOYB-RHfc_r"}},{"cell_type":"code","source":["import torch\n","import numpy as np"],"metadata":{"id":"3BNXSR-VdYKQ","executionInfo":{"status":"ok","timestamp":1728737006245,"user_tz":-180,"elapsed":10566,"user":{"displayName":"Andrii Tsup","userId":"01764732116425569990"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","execution_count":2,"metadata":{"id":"QLKZ77x4v_-v","executionInfo":{"status":"ok","timestamp":1728737006246,"user_tz":-180,"elapsed":9,"user":{"displayName":"Andrii Tsup","userId":"01764732116425569990"}}},"outputs":[],"source":["# Вхідні дані (temp, rainfall, humidity)\n","inputs = np.array([[73, 67, 43],\n","                   [91, 88, 64],\n","                   [87, 134, 58],\n","                   [102, 43, 37],\n","                   [69, 96, 70]], dtype='float32')\n","\n","# Таргети (apples > 80)\n","targets = np.array([[0],\n","                    [1],\n","                    [1],\n","                    [0],\n","                    [1]], dtype='float32')"]},{"cell_type":"code","source":["inputs_tensor = torch.from_numpy(inputs)\n","targets_tensor = torch.from_numpy(targets)\n","print(inputs_tensor)\n","print(targets_tensor)"],"metadata":{"id":"KjoeaDrk6fO7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1728737006246,"user_tz":-180,"elapsed":8,"user":{"displayName":"Andrii Tsup","userId":"01764732116425569990"}},"outputId":"fdd5405e-6ba1-4d1e-87ea-65cceafa10de"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ 73.,  67.,  43.],\n","        [ 91.,  88.,  64.],\n","        [ 87., 134.,  58.],\n","        [102.,  43.,  37.],\n","        [ 69.,  96.,  70.]])\n","tensor([[0.],\n","        [1.],\n","        [1.],\n","        [0.],\n","        [1.]])\n"]}]},{"cell_type":"markdown","source":["2. Ініціюйте ваги `w`, `b` для моделі логістичної регресії потрібної форми зважаючи на розмірності даних випадковими значеннями з нормального розподілу. Лишаю тут код для фіксації `random_seed`."],"metadata":{"id":"iKzbJKfOgGV8"}},{"cell_type":"code","source":["torch.random.manual_seed(1)\n","w = torch.randn(1, 3, requires_grad=True)\n","b = torch.randn(1, requires_grad=True)\n","\n","print(\"Ваги w:\", w)\n","print(\"Зміщення b:\", b)"],"metadata":{"id":"aXhKw6Tdj1-d","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1728737007179,"user_tz":-180,"elapsed":940,"user":{"displayName":"Andrii Tsup","userId":"01764732116425569990"}},"outputId":"62d3638d-0ed0-433d-ab32-ab39418ebd16"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Ваги w: tensor([[0.6614, 0.2669, 0.0617]], requires_grad=True)\n","Зміщення b: tensor([0.6213], requires_grad=True)\n"]}]},{"cell_type":"markdown","source":["Кількість ознак 3, цільова змінна 1, то ж w повинен мати розмірність (1,3), b - скаляр (1,)"],"metadata":{"id":"sUlXMIG3Pg2o"}},{"cell_type":"markdown","source":["3. Напишіть функцію `model`, яка буде обчислювати функцію гіпотези в логістичній регресії і дозволяти робити передбачення на основі введеного рядка даних і коефіцієнтів в змінних `w`, `b`.\n","\n","  **Важливий момент**, що функція `model` робить обчислення на `torch.tensors`, тож для математичних обчислень використовуємо фукнціонал `torch`, наприклад:\n","  - обчсилення $e^x$: `torch.exp(x)`\n","  - обчсилення $log(x)$: `torch.log(x)`\n","  - обчислення середнього значення вектору `x`: `torch.mean(x)`\n","\n","  Використайте функцію `model` для обчислення передбачень з поточними значеннями `w`, `b`.Виведіть результат обчислень на екран.\n","\n","  Проаналізуйте передбачення. Чи не викликають вони у вас підозр? І якщо викликають, то чим це може бути зумовлено?"],"metadata":{"id":"nYGxNGTaf5s6"}},{"cell_type":"code","source":["def model(x, w, b):\n","  z = x@w.T + b\n","  hyp = 1 / (1 + torch.exp(-z))\n","  return hyp"],"metadata":{"id":"pSz2j4Fh6jBv","executionInfo":{"status":"ok","timestamp":1728737007179,"user_tz":-180,"elapsed":31,"user":{"displayName":"Andrii Tsup","userId":"01764732116425569990"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["pred = model(inputs_tensor, w, b)\n","print(pred)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eNCcQyVpsv2m","executionInfo":{"status":"ok","timestamp":1728737007180,"user_tz":-180,"elapsed":32,"user":{"displayName":"Andrii Tsup","userId":"01764732116425569990"}},"outputId":"7db2fa08-dc91-4986-b355-aa36126b3b39"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [1.]], grad_fn=<MulBackward0>)\n"]}]},{"cell_type":"markdown","source":["Всі передбачення 1. Це, напевно, через великі значення випадкових w та b."],"metadata":{"id":"YnOgnt7TwRYT"}},{"cell_type":"markdown","source":["4. Напишіть функцію `binary_cross_entropy`, яка приймає на вхід передбачення моделі `predicted_probs` та справжні мітки в даних `true_labels` і обчислює значення втрат (loss)  за формулою бінарної крос-ентропії для кожного екземпляра та вертає середні втрати по всьому набору даних.\n","  Використайте функцію `binary_cross_entropy` для обчислення втрат для поточних передбачень моделі."],"metadata":{"id":"O2AGM0Mb2yHa"}},{"cell_type":"code","source":["def binary_cross_entropy(predicted_probs, true_labels):\n","  epsilon = 1e-10 # Small value to avoid problem with log(0)\n","  loss = -(true_labels * torch.log(predicted_probs + epsilon) + (1 - true_labels) * torch.log(1 - predicted_probs + epsilon))\n","\n","  return torch.mean(loss)"],"metadata":{"id":"1bWlovvx6kZS","executionInfo":{"status":"ok","timestamp":1728737007180,"user_tz":-180,"elapsed":31,"user":{"displayName":"Andrii Tsup","userId":"01764732116425569990"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["loss = binary_cross_entropy(pred, targets_tensor)\n","print('Втрати предебачень', loss)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_h8HEUns193i","executionInfo":{"status":"ok","timestamp":1728737007180,"user_tz":-180,"elapsed":30,"user":{"displayName":"Andrii Tsup","userId":"01764732116425569990"}},"outputId":"5c352c97-79ce-454c-f09e-87d2826d510a"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Втрати предебачень tensor(9.2103, grad_fn=<MeanBackward0>)\n"]}]},{"cell_type":"markdown","source":["5. Зробіть зворотнє поширення помилки і виведіть градієнти за параметрами `w`, `b`. Проаналізуйте їх значення. Як гадаєте, чому вони саме такі?"],"metadata":{"id":"ZFKpQxdHi1__"}},{"cell_type":"code","source":["loss.backward()"],"metadata":{"id":"YAbXUNSJ6mCl","executionInfo":{"status":"ok","timestamp":1728737007180,"user_tz":-180,"elapsed":28,"user":{"displayName":"Andrii Tsup","userId":"01764732116425569990"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["print(w.grad)\n","print(b.grad)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o766N6s1H5Ta","executionInfo":{"status":"ok","timestamp":1728737007180,"user_tz":-180,"elapsed":27,"user":{"displayName":"Andrii Tsup","userId":"01764732116425569990"}},"outputId":"b8adbf5c-e620-4c73-99d4-3a2473eb815b"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1.0201e-19, 9.3628e-20, 6.0090e-20]])\n","tensor([1.3974e-21])\n"]}]},{"cell_type":"markdown","source":["Скористався додаванням дуже маленького значення, щоб loss і градієнти хоч якось відображались. Градієнти мають дуже мале значення через великі ініційовані ваги та натуральні(не масштабовані/нормалізовані вхідні дані). Оскільки логістична регресія чутлива до масштабів то виникає така ситуація."],"metadata":{"id":"hh3gn1HFLmip"}},{"cell_type":"markdown","source":["**Що сталось?**\n","\n","В цій задачі, коли ми ініціювали значення випадковими значеннями з нормального розподілу, насправді ці значення не були дуже гарними стартовими значеннями і привели до того, що градієнти стали дуже малими або навіть рівними нулю (це призводить до того, що градієнти \"зникають\"), і відповідно при оновленні ваг у нас не буде нічого змінюватись. Це називається `gradient vanishing`. Це відбувається через **насичення сигмоїдної функції активації.**\n","\n","У нашій задачі ми використовуємо сигмоїдну функцію активації, яка має такий вигляд:\n","\n","   $$\n","   \\sigma(z) = \\frac{1}{1 + e^{-z}}\n","   $$\n","\n","\n","Коли значення $z$ дуже велике або дуже мале, сигмоїдна функція починає \"насичуватись\". Це означає, що для великих позитивних $z$ сигмоїда наближається до 1, а для великих негативних — до 0. В цих діапазонах градієнти починають стрімко зменшуватись і наближаються до нуля (бо градієнт - це похідна, похідна на проміжку функції, де вона паралельна осі ОХ, дорівнює 0), що робить оновлення ваг неможливим.\n","\n","![](https://editor.analyticsvidhya.com/uploads/27889vaegp.png)\n","\n","У логістичній регресії $ z = x \\cdot w + b $. Якщо ваги $w, b$ - великі, значення $z$ також буде великим, і сигмоїда перейде в насичену область, де градієнти дуже малі.\n","\n","Саме це сталося в нашій задачі, де великі випадкові значення ваг викликали насичення сигмоїдної функції. Це в свою чергу призводить до того, що під час зворотного поширення помилки (backpropagation) модель оновлює ваги дуже повільно або зовсім не оновлює. Це називається проблемою **зникнення градієнтів** (gradient vanishing problem).\n","\n","**Що ж робити?**\n","Ініціювати ваги маленькими значеннями навколо нуля. Наприклад ми можемо просто в існуючій ініціалізації ваги розділити на 1000. Можна також використати інший спосіб ініціалізації вагів - інформація про це [тут](https://www.geeksforgeeks.org/initialize-weights-in-pytorch/).\n","\n","Як це робити - показую нижче. **Виконайте код та знову обчисліть передбачення, лосс і виведіть градієнти.**\n","\n","А я пишу пояснення, чому просто не зробити\n","\n","```\n","w = torch.randn(1, 3, requires_grad=True)/1000\n","b = torch.randn(1, requires_grad=True)/1000\n","```\n","\n","Нам потрібно, аби тензори вагів були листовими (leaf tensors).\n","\n","1. **Що таке листовий тензор**\n","Листовий тензор — це тензор, який був створений користувачем безпосередньо і з якого починається обчислювальний граф. Якщо такий тензор має `requires_grad=True`, PyTorch буде відслідковувати всі операції, виконані над ним, щоб правильно обчислювати градієнти під час навчання.\n","\n","2. **Чому ми використовуємо `w.data` замість звичайних операцій**\n","Якщо ми просто виконали б операції, такі як `(w - 0.5) / 100`, ми б отримали **новий тензор**, який вже не був би листовим тензором, оскільки ці операції створюють **новий** тензор, а не модифікують існуючий.\n","\n","  Проте, щоб залишити наші тензори ваги `w` та зміщення `b` листовими і продовжити можливість відстеження градієнтів під час тренування, ми використовуємо атрибут `.data`. Цей атрибут дозволяє **виконувати операції in-place (прямо на існуючому тензорі)** без зміни самого об'єкта тензора. Отже, тензор залишається листовим, і PyTorch може коректно обчислювати його градієнти.\n","\n","3. **Чому важливо залишити тензор листовим**\n","Якщо тензор більше не є листовим (наприклад, через проведення операцій, що створюють нові тензори), ви не зможете отримати градієнти за допомогою `w.grad` чи `b.grad` після виклику `loss.backward()`. Це може призвести до втрати можливості оновлення параметрів під час тренування моделі. В нашому випадку ми хочемо, щоб тензори `w` та `b` накопичували градієнти, тому вони повинні залишатись листовими.\n","\n","**Висновок:**\n","Ми використовуємо `.data`, щоб виконати операції зміни значень на ваги і зміщення **in-place**, залишаючи їх листовими тензорами, які можуть накопичувати градієнти під час навчання. Це дозволяє коректно працювати механізму зворотного поширення помилки (backpropagation) і оновлювати ваги моделі."],"metadata":{"id":"nDN1t1RujQsK"}},{"cell_type":"markdown","source":["5. Виконайте код та знову обчисліть передбачення, лосс і знайдіть градієнти та виведіть всі ці тензори на екран."],"metadata":{"id":"rOPSQyttpVjO"}},{"cell_type":"code","source":["torch.random.manual_seed(1)\n","w = torch.randn(1, 3, requires_grad=True)  # Листовий тензор\n","b = torch.randn(1, requires_grad=True)     # Листовий тензор\n","\n","# in-place операції\n","w.data = w.data / 1000\n","b.data = b.data / 1000"],"metadata":{"id":"-EBOJ3tsnRaD","executionInfo":{"status":"ok","timestamp":1728737007180,"user_tz":-180,"elapsed":24,"user":{"displayName":"Andrii Tsup","userId":"01764732116425569990"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["pred = model(inputs_tensor, w, b)\n","print(pred)"],"metadata":{"id":"-JwXiSpX6orh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1728737007181,"user_tz":-180,"elapsed":24,"user":{"displayName":"Andrii Tsup","userId":"01764732116425569990"}},"outputId":"561fcc1b-4798-4020-daf7-dcce5375532b"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0.5174],\n","        [0.5220],\n","        [0.5244],\n","        [0.5204],\n","        [0.5190]], grad_fn=<MulBackward0>)\n"]}]},{"cell_type":"code","source":["def binary_cross_entropy(predicted_probs, true_labels):\n","\n","    loss = -(true_labels * torch.log(predicted_probs) + (1 - true_labels) * torch.log(1 - predicted_probs))\n","\n","    return torch.mean(loss)"],"metadata":{"id":"Pj0XO1vySh_B","executionInfo":{"status":"ok","timestamp":1728737007181,"user_tz":-180,"elapsed":19,"user":{"displayName":"Andrii Tsup","userId":"01764732116425569990"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["loss = binary_cross_entropy(pred, targets_tensor)\n","print('Втрати предебачень', loss)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ym18J_zsS2EL","executionInfo":{"status":"ok","timestamp":1728737007181,"user_tz":-180,"elapsed":18,"user":{"displayName":"Andrii Tsup","userId":"01764732116425569990"}},"outputId":"aef9147d-30a2-4ebd-bdaa-c20b1fe3e25f"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Втрати предебачень tensor(0.6829, grad_fn=<MeanBackward0>)\n"]}]},{"cell_type":"code","source":["loss.backward()"],"metadata":{"executionInfo":{"status":"ok","timestamp":1728737007181,"user_tz":-180,"elapsed":16,"user":{"displayName":"Andrii Tsup","userId":"01764732116425569990"}},"id":"BEp87pW0Say-"},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["print(w.grad)\n","print(b.grad)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1728737007181,"user_tz":-180,"elapsed":16,"user":{"displayName":"Andrii Tsup","userId":"01764732116425569990"}},"outputId":"8d4131f9-bb8c-476a-bd63-0962d6c42f23","id":"xl8qONW9Say_"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ -5.4417, -18.9853, -10.0682]])\n","tensor([-0.0794])\n"]}]},{"cell_type":"markdown","source":["6. Напишіть алгоритм градієнтного спуску, який буде навчати модель з використанням написаних раніше функцій і виконуючи оновлення ваг. Алгоритм має включати наступні кроки:\n","\n","  1. Генерація прогнозів\n","  2. Обчислення втрат\n","  3. Обчислення градієнтів (gradients) loss-фукнції відносно ваг і зсувів\n","  4. Налаштування ваг шляхом віднімання невеликої величини, пропорційної градієнту (`learning_rate` домножений на градієнт)\n","  5. Скидання градієнтів на нуль\n","\n","Виконайте градієнтний спуск протягом 1000 епох, обчисліть фінальні передбачення і проаналізуйте, чи вони точні?"],"metadata":{"id":"RCdi44IT334o"}},{"cell_type":"code","source":["def binary_cross_entropy(predicted_probs, true_labels):\n","    epsilon = 1e-8  # дуже маленьке значення для уникнення log(0)\n","    predicted_probs = torch.clamp(predicted_probs, epsilon, 1 - epsilon)\n","    loss = -(true_labels * torch.log(predicted_probs + epsilon) + (1 - true_labels) * torch.log(1 - predicted_probs + epsilon))\n","\n","    return torch.mean(loss)"],"metadata":{"id":"c9RSiFLLmRh7","executionInfo":{"status":"ok","timestamp":1728737007181,"user_tz":-180,"elapsed":13,"user":{"displayName":"Andrii Tsup","userId":"01764732116425569990"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["inputs_tensor = (inputs_tensor - inputs_tensor.mean(dim=0)) / inputs_tensor.std(dim=0)\n"],"metadata":{"id":"GD8oYkEPw1ZI","executionInfo":{"status":"ok","timestamp":1728737007181,"user_tz":-180,"elapsed":13,"user":{"displayName":"Andrii Tsup","userId":"01764732116425569990"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["def full_batch_gradient_descent(X, y, w, b, lr=0.01, epochs=1000):\n","    for epochs in range(epochs):\n","        #Генерація прогнозів\n","        pred = model(X, w, b)\n","\n","        #Обчислення втрат\n","        loss = binary_cross_entropy(pred, y)\n","\n","        #Обчислення градієнтів\n","        loss.backward()\n","\n","        #Налаштування ваг\n","        with torch.no_grad():  # Щоб PyTorch не обчислював градієнти під час оновлення ваг\n","            w.data -= lr * w.grad\n","            b.data -= lr * b.grad\n","\n","        #Обнулення градієнтів\n","        w.grad.zero_()\n","        b.grad.zero_()\n","\n","        if (epochs + 1) % 100 == 0:\n","            print(f\"Epoch [{epochs+1}/{epochs}], Loss: {loss.item():.4f}\")\n","            print(\"Weights after epoch:\", w)\n","            print(\"Bias after epoch:\", b)\n","            print(\"Gradients for weights:\", w.grad)\n","            print(\"Gradients for bias:\", b.grad)"],"metadata":{"id":"mObHPyE06qsO","executionInfo":{"status":"ok","timestamp":1728737007181,"user_tz":-180,"elapsed":12,"user":{"displayName":"Andrii Tsup","userId":"01764732116425569990"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["full_batch_gradient_descent(inputs_tensor, targets_tensor, w, b)"],"metadata":{"id":"Zc8HD_inr33l","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1728737009208,"user_tz":-180,"elapsed":2038,"user":{"displayName":"Andrii Tsup","userId":"01764732116425569990"}},"outputId":"2e391597-2fc7-482f-9251-6f31551b959e"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [100/99], Loss: 0.4129\n","Weights after epoch: tensor([[0.0005, 0.4533, 0.4196]], requires_grad=True)\n","Bias after epoch: tensor([0.0895], requires_grad=True)\n","Gradients for weights: tensor([[0., 0., 0.]])\n","Gradients for bias: tensor([0.])\n","Epoch [200/199], Loss: 0.3123\n","Weights after epoch: tensor([[-0.0173,  0.6443,  0.6606]], requires_grad=True)\n","Bias after epoch: tensor([0.1581], requires_grad=True)\n","Gradients for weights: tensor([[0., 0., 0.]])\n","Gradients for bias: tensor([0.])\n","Epoch [300/299], Loss: 0.2501\n","Weights after epoch: tensor([[-0.0172,  0.7916,  0.8530]], requires_grad=True)\n","Bias after epoch: tensor([0.2127], requires_grad=True)\n","Gradients for weights: tensor([[0., 0., 0.]])\n","Gradients for bias: tensor([0.])\n","Epoch [400/399], Loss: 0.2082\n","Weights after epoch: tensor([[-0.0081,  0.9103,  1.0128]], requires_grad=True)\n","Bias after epoch: tensor([0.2574], requires_grad=True)\n","Gradients for weights: tensor([[0., 0., 0.]])\n","Gradients for bias: tensor([0.])\n","Epoch [500/499], Loss: 0.1781\n","Weights after epoch: tensor([[0.0055, 1.0091, 1.1493]], requires_grad=True)\n","Bias after epoch: tensor([0.2948], requires_grad=True)\n","Gradients for weights: tensor([[0., 0., 0.]])\n","Gradients for bias: tensor([0.])\n","Epoch [600/599], Loss: 0.1554\n","Weights after epoch: tensor([[0.0213, 1.0936, 1.2684]], requires_grad=True)\n","Bias after epoch: tensor([0.3269], requires_grad=True)\n","Gradients for weights: tensor([[0., 0., 0.]])\n","Gradients for bias: tensor([0.])\n","Epoch [700/699], Loss: 0.1377\n","Weights after epoch: tensor([[0.0380, 1.1671, 1.3740]], requires_grad=True)\n","Bias after epoch: tensor([0.3548], requires_grad=True)\n","Gradients for weights: tensor([[0., 0., 0.]])\n","Gradients for bias: tensor([0.])\n","Epoch [800/799], Loss: 0.1236\n","Weights after epoch: tensor([[0.0550, 1.2321, 1.4688]], requires_grad=True)\n","Bias after epoch: tensor([0.3796], requires_grad=True)\n","Gradients for weights: tensor([[0., 0., 0.]])\n","Gradients for bias: tensor([0.])\n","Epoch [900/899], Loss: 0.1120\n","Weights after epoch: tensor([[0.0720, 1.2902, 1.5548]], requires_grad=True)\n","Bias after epoch: tensor([0.4018], requires_grad=True)\n","Gradients for weights: tensor([[0., 0., 0.]])\n","Gradients for bias: tensor([0.])\n","Epoch [1000/999], Loss: 0.1024\n","Weights after epoch: tensor([[0.0886, 1.3427, 1.6335]], requires_grad=True)\n","Bias after epoch: tensor([0.4220], requires_grad=True)\n","Gradients for weights: tensor([[0., 0., 0.]])\n","Gradients for bias: tensor([0.])\n"]}]},{"cell_type":"code","source":["with torch.no_grad():\n","    final_predictions = model(inputs_tensor, w, b)\n","    print(\"\\nФінальні передбачення після навчання:\")\n","    print(final_predictions)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uS0E4xKYiOdX","executionInfo":{"status":"ok","timestamp":1728737009209,"user_tz":-180,"elapsed":10,"user":{"displayName":"Andrii Tsup","userId":"01764732116425569990"}},"outputId":"bfde7d71-28e1-4ce2-aba5-32f46c8e51c9"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Фінальні передбачення після навчання:\n","tensor([[0.1518],\n","        [0.8432],\n","        [0.9412],\n","        [0.0399],\n","        [0.9279]])\n"]}]},{"cell_type":"code","execution_count":22,"metadata":{"_uuid":"dbf5bca8cbf2a3831089b454c70469e3748e9682","id":"xIMLhrfsentv","executionInfo":{"status":"ok","timestamp":1728737009209,"user_tz":-180,"elapsed":7,"user":{"displayName":"Andrii Tsup","userId":"01764732116425569990"}}},"outputs":[],"source":["# MSE loss\n","def mse(t1, t2):\n","    diff = t1 - t2\n","    return torch.sum(diff * diff) / diff.numel()"]},{"cell_type":"code","execution_count":23,"metadata":{"_uuid":"90da6779aad81608c40cdca77c3c04b68a815c11","colab":{"base_uri":"https://localhost:8080/"},"id":"67EGJNgWentv","executionInfo":{"status":"ok","timestamp":1728737009557,"user_tz":-180,"elapsed":355,"user":{"displayName":"Andrii Tsup","userId":"01764732116425569990"}},"outputId":"1fa0050a-dcde-49fa-e280-602595798ad3"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(0.0116)\n"]}],"source":["# Обчислимо loss\n","losss = mse(final_predictions, targets_tensor)\n","print(losss)"]},{"cell_type":"markdown","source":["Модель чудово підігналась під дані\n","\n","Довелось відмасштабувати вхідні дані, інакше виходили дуже маленькі значення передбачень."],"metadata":{"id":"H2ko3Dg6x5Nr"}},{"cell_type":"markdown","source":["**Секція 2. Створення лог регресії з використанням функціоналу `torch.nn`.**\n","\n","Давайте повторно реалізуємо ту ж модель, використовуючи деякі вбудовані функції та класи з PyTorch.\n","\n","Даних у нас буде побільше - тож, визначаємо нові масиви."],"metadata":{"id":"fuRhlyF9qAia"}},{"cell_type":"code","source":["import torch.nn as nn"],"metadata":{"id":"41C3sCQJyf1e","executionInfo":{"status":"ok","timestamp":1728737009558,"user_tz":-180,"elapsed":20,"user":{"displayName":"Andrii Tsup","userId":"01764732116425569990"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["# Вхідні дані (temp, rainfall, humidity)\n","inputs = np.array([[73, 67, 43],\n","                   [91, 88, 64],\n","                   [87, 134, 58],\n","                   [102, 43, 37],\n","                   [69, 96, 70],\n","                   [73, 67, 43],\n","                   [91, 88, 64],\n","                   [87, 134, 58],\n","                   [102, 43, 37],\n","                   [69, 96, 70],\n","                   [73, 67, 43],\n","                   [91, 88, 64],\n","                   [87, 134, 58],\n","                   [102, 43, 37],\n","                   [69, 96, 70]], dtype='float32')\n","\n","# Таргети (apples > 80)\n","targets = np.array([[0],\n","                    [1],\n","                    [1],\n","                    [0],\n","                    [1],\n","                    [0],\n","                    [1],\n","                    [1],\n","                    [0],\n","                    [1],\n","                    [0],\n","                    [1],\n","                    [1],\n","                    [0],\n","                    [1]], dtype='float32')"],"metadata":{"id":"IX8Bhm74rV4M","executionInfo":{"status":"ok","timestamp":1728740287279,"user_tz":-180,"elapsed":315,"user":{"displayName":"Andrii Tsup","userId":"01764732116425569990"}}},"execution_count":72,"outputs":[]},{"cell_type":"code","source":["inputs = torch.from_numpy(inputs)\n","targets = torch.from_numpy(targets)"],"metadata":{"id":"j7O3a0xFyrI6","executionInfo":{"status":"ok","timestamp":1728740289906,"user_tz":-180,"elapsed":313,"user":{"displayName":"Andrii Tsup","userId":"01764732116425569990"}}},"execution_count":73,"outputs":[]},{"cell_type":"code","source":["inputs"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9PYx29YGysbu","executionInfo":{"status":"ok","timestamp":1728740291972,"user_tz":-180,"elapsed":328,"user":{"displayName":"Andrii Tsup","userId":"01764732116425569990"}},"outputId":"5580caf9-e142-4af0-cdf6-4d7f005677f8"},"execution_count":74,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 73.,  67.,  43.],\n","        [ 91.,  88.,  64.],\n","        [ 87., 134.,  58.],\n","        [102.,  43.,  37.],\n","        [ 69.,  96.,  70.],\n","        [ 73.,  67.,  43.],\n","        [ 91.,  88.,  64.],\n","        [ 87., 134.,  58.],\n","        [102.,  43.,  37.],\n","        [ 69.,  96.,  70.],\n","        [ 73.,  67.,  43.],\n","        [ 91.,  88.,  64.],\n","        [ 87., 134.,  58.],\n","        [102.,  43.,  37.],\n","        [ 69.,  96.,  70.]])"]},"metadata":{},"execution_count":74}]},{"cell_type":"markdown","source":["7. Завантажте вхідні дані та мітки в PyTorch тензори та з них створіть датасет, який поєднує вхідні дані з мітками, використовуючи клас `TensorDataset`. Виведіть перші 3 елементи в датасеті.\n","\n"],"metadata":{"id":"7X2dV30KtAPu"}},{"cell_type":"code","source":["from torch.utils.data import TensorDataset, DataLoader"],"metadata":{"id":"chrvMfBs6vjo","executionInfo":{"status":"ok","timestamp":1728737009558,"user_tz":-180,"elapsed":13,"user":{"displayName":"Andrii Tsup","userId":"01764732116425569990"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["train_ds = TensorDataset(inputs, targets)\n","train_ds[0:3]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P33QF68d0-Vw","executionInfo":{"status":"ok","timestamp":1728740680017,"user_tz":-180,"elapsed":327,"user":{"displayName":"Andrii Tsup","userId":"01764732116425569990"}},"outputId":"b6209ff0-525e-40d2-ac27-e212fbfe2193"},"execution_count":81,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[ 73.,  67.,  43.],\n","         [ 91.,  88.,  64.],\n","         [ 87., 134.,  58.]]),\n"," tensor([[0.],\n","         [1.],\n","         [1.]]))"]},"metadata":{},"execution_count":81}]},{"cell_type":"markdown","source":["8. Визначте data loader з класом **DataLoader** для підготовленого датасету `train_ds`, встановіть розмір батчу на 5 та увімкніть перемішування даних для ефективного навчання моделі. Виведіть перший елемент в дата лоадері."],"metadata":{"id":"4nMFaa8suOd3"}},{"cell_type":"code","source":["batch_size = 5\n","train_dl = DataLoader(train_ds, batch_size, shuffle=True)\n"],"metadata":{"id":"ZCsRo5Mx6wEI","executionInfo":{"status":"ok","timestamp":1728740683404,"user_tz":-180,"elapsed":346,"user":{"displayName":"Andrii Tsup","userId":"01764732116425569990"}}},"execution_count":82,"outputs":[]},{"cell_type":"code","source":["batch = next(iter(train_dl))\n","inputs, labels = batch\n","\n","first_input = inputs[0]\n","first_label = labels[0]\n","\n","print(\"First input:\", first_input)\n","print(\"First label:\", first_label)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NVD4FUK83Jca","executionInfo":{"status":"ok","timestamp":1728740166927,"user_tz":-180,"elapsed":456,"user":{"displayName":"Andrii Tsup","userId":"01764732116425569990"}},"outputId":"d22fd128-d74b-420b-df6b-39114adabbfd"},"execution_count":69,"outputs":[{"output_type":"stream","name":"stdout","text":["First input: tensor([ 87., 134.,  58.])\n","First label: tensor([1.])\n"]}]},{"cell_type":"markdown","source":["9. Створіть клас `LogReg` для логістичної регресії, наслідуючи модуль `torch.nn.Module` за прикладом в лекції (в частині про FeedForward мережі).\n","\n","  У нас модель складається з лінійної комбінації вхідних значень і застосування фукнції сигмоїда. Тож, нейромережа буде складатись з лінійного шару `nn.Linear` і використання активації `nn.Sigmid`. У створеному класі мають бути реалізовані методи `__init__` з ініціалізацією шарів і метод `forward` для виконання прямого проходу моделі через лінійний шар і функцію активації.\n","\n","  Створіть екземпляр класу `LogReg` в змінній `model`."],"metadata":{"id":"ymcQOo_hum6I"}},{"cell_type":"code","source":["class LogReg(nn.Module):\n","    # Initialize the layers\n","    def __init__(self):\n","        super().__init__()\n","        self.linear1 = nn.Linear(3, 1)\n","        self.act1 = nn.Sigmoid() # Activation function\n","\n","    def forward(self, x):\n","        x = self.linear1(x)\n","        x = self.act1(x)\n","        return x"],"metadata":{"id":"EyAwhTBW6xxz","executionInfo":{"status":"ok","timestamp":1728740130180,"user_tz":-180,"elapsed":305,"user":{"displayName":"Andrii Tsup","userId":"01764732116425569990"}}},"execution_count":63,"outputs":[]},{"cell_type":"code","source":["model = LogReg()"],"metadata":{"id":"RvWfzXPf0oVT","executionInfo":{"status":"ok","timestamp":1728740131576,"user_tz":-180,"elapsed":271,"user":{"displayName":"Andrii Tsup","userId":"01764732116425569990"}}},"execution_count":64,"outputs":[]},{"cell_type":"markdown","source":["10. Задайте оптимізатор `Stockastic Gradient Descent` в змінній `opt` для навчання моделі логістичної регресії. А також визначіть в змінній `loss` функцію втрат `binary_cross_entropy` з модуля `torch.nn.functional` для обчислення втрат моделі. Обчисліть втрати для поточних передбачень і міток, а потім виведіть їх. Зробіть висновок, чи моделі вдалось навчитись?"],"metadata":{"id":"RflV7xeVyoJy"}},{"cell_type":"code","source":["import torch.nn.functional as F"],"metadata":{"id":"wZ0vvW705dgm","executionInfo":{"status":"ok","timestamp":1728739464241,"user_tz":-180,"elapsed":292,"user":{"displayName":"Andrii Tsup","userId":"01764732116425569990"}}},"execution_count":39,"outputs":[]},{"cell_type":"code","source":["opt = torch.optim.SGD(model.parameters(), lr=1e-5)\n","\n","loss_fn = F.binary_cross_entropy\n","loss = loss_fn(model(inputs), targets)\n","print(loss)"],"metadata":{"id":"3QCATPU_6yfa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1728741040100,"user_tz":-180,"elapsed":274,"user":{"displayName":"Andrii Tsup","userId":"01764732116425569990"}},"outputId":"4949d129-89cf-45a7-ef99-9dcbd64a9fc1"},"execution_count":90,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(5.1916, grad_fn=<BinaryCrossEntropyBackward0>)\n"]}]},{"cell_type":"markdown","source":["11. Візьміть з лекції функцію для тренування моделі з відстеженням значень втрат і навчіть щойно визначену модель на 1000 епохах. Виведіть після цього графік зміни loss, фінальні передбачення і значення таргетів."],"metadata":{"id":"ch-WrYnKzMzq"}},{"cell_type":"code","source":["# Модифікована функцію fit для відстеження втрат\n","def fit_return_loss(num_epochs, model, loss_fn, opt, train_dl):\n","    losses = []\n","    for epoch in range(num_epochs):\n","        # Ініціалізуємо акумулятор для втрат\n","        total_loss = 0\n","\n","        for xb, yb in train_dl:\n","            # Генеруємо передбачення\n","            pred = model(xb)\n","\n","            # Обчислюємо втрати\n","            loss = loss_fn(pred, yb)\n","\n","            # Виконуємо градієнтний спуск\n","            loss.backward()\n","            opt.step()\n","            opt.zero_grad()\n","\n","            # Накопичуємо втрати\n","            total_loss += loss.item()\n","\n","        # Обчислюємо середні втрати для епохи\n","        avg_loss = total_loss / len(train_dl)\n","        losses.append(avg_loss)\n","\n","        # Виводимо підсумок епохи\n","        if (epoch + 1) % 50 == 0:\n","          print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}')\n","    return losses"],"metadata":{"id":"rPUEoOIQielJ","executionInfo":{"status":"ok","timestamp":1728741063647,"user_tz":-180,"elapsed":309,"user":{"displayName":"Andrii Tsup","userId":"01764732116425569990"}}},"execution_count":92,"outputs":[]},{"cell_type":"code","source":["loss = fit_return_loss(1000, model, loss_fn, opt, train_dl)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uGCN_SMb90UA","executionInfo":{"status":"ok","timestamp":1728741066646,"user_tz":-180,"elapsed":2005,"user":{"displayName":"Andrii Tsup","userId":"01764732116425569990"}},"outputId":"2681a5bb-5525-4154-81fe-1cb5a50080a8"},"execution_count":93,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [50/1000], Loss: 0.7788\n","Epoch [100/1000], Loss: 0.7693\n","Epoch [150/1000], Loss: 0.7564\n","Epoch [200/1000], Loss: 0.7494\n","Epoch [250/1000], Loss: 0.7394\n","Epoch [300/1000], Loss: 0.7284\n","Epoch [350/1000], Loss: 0.7219\n","Epoch [400/1000], Loss: 0.7146\n","Epoch [450/1000], Loss: 0.7043\n","Epoch [500/1000], Loss: 0.6983\n","Epoch [550/1000], Loss: 0.6924\n","Epoch [600/1000], Loss: 0.6866\n","Epoch [650/1000], Loss: 0.6769\n","Epoch [700/1000], Loss: 0.6734\n","Epoch [750/1000], Loss: 0.6642\n","Epoch [800/1000], Loss: 0.6588\n","Epoch [850/1000], Loss: 0.6527\n","Epoch [900/1000], Loss: 0.6478\n","Epoch [950/1000], Loss: 0.6436\n","Epoch [1000/1000], Loss: 0.6401\n"]}]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","plt.plot(loss)\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":451},"id":"cdpb1bgH_9vF","executionInfo":{"status":"ok","timestamp":1728741108443,"user_tz":-180,"elapsed":1166,"user":{"displayName":"Andrii Tsup","userId":"01764732116425569990"}},"outputId":"f6033206-dd50-4f13-b90e-ed6c051d29f1"},"execution_count":94,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["preds = model(inputs)\n","preds"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vu0TWN-FAFZf","executionInfo":{"status":"ok","timestamp":1728741139708,"user_tz":-180,"elapsed":282,"user":{"displayName":"Andrii Tsup","userId":"01764732116425569990"}},"outputId":"752b6072-a0c2-4ccf-df73-272d3eead1de"},"execution_count":95,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0.8950],\n","        [0.4652],\n","        [1.0000],\n","        [0.0022],\n","        [0.8498],\n","        [0.8950],\n","        [0.4652],\n","        [1.0000],\n","        [0.0022],\n","        [0.8498],\n","        [0.8950],\n","        [0.4652],\n","        [1.0000],\n","        [0.0022],\n","        [0.8498]], grad_fn=<SigmoidBackward0>)"]},"metadata":{},"execution_count":95}]},{"cell_type":"code","source":["preds.int()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LhO5fzgkAJ5h","executionInfo":{"status":"ok","timestamp":1728741156599,"user_tz":-180,"elapsed":295,"user":{"displayName":"Andrii Tsup","userId":"01764732116425569990"}},"outputId":"31bc5690-1756-43c3-a29e-437412bb6fc1"},"execution_count":96,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0],\n","        [0],\n","        [1],\n","        [0],\n","        [0],\n","        [0],\n","        [0],\n","        [1],\n","        [0],\n","        [0],\n","        [0],\n","        [0],\n","        [1],\n","        [0],\n","        [0]], dtype=torch.int32)"]},"metadata":{},"execution_count":96}]},{"cell_type":"code","source":["targets"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qxPKmWeXAM1j","executionInfo":{"status":"ok","timestamp":1728741169212,"user_tz":-180,"elapsed":304,"user":{"displayName":"Andrii Tsup","userId":"01764732116425569990"}},"outputId":"f68641d5-e956-4985-b60a-ee51f48ddd97"},"execution_count":97,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0.],\n","        [1.],\n","        [1.],\n","        [0.],\n","        [1.],\n","        [0.],\n","        [1.],\n","        [1.],\n","        [0.],\n","        [1.],\n","        [0.],\n","        [1.],\n","        [1.],\n","        [0.],\n","        [1.]])"]},"metadata":{},"execution_count":97}]}]}